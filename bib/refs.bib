@article{KNOTH2024100225,
    title = {AI literacy and its implications for prompt engineering strategies},
    journal = {Computers and Education: Artificial Intelligence},
    volume = {6},
    pages = {100225},
    year = {2024},
    issn = {2666-920X},
    doi = {https://doi.org/10.1016/j.caeai.2024.100225},
    url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000262},
    author = {Nils Knoth and Antonia Tolzin and Andreas Janson and Jan Marco Leimeister},
}

@book{Dignum_2019, 
    title={Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way}, 
    ISBN={9783030303716}, 
    ISSN={2365-306X}, 
    url={http://dx.doi.org/10.1007/978-3-030-30371-6}, 
    DOI={10.1007/978-3-030-30371-6}, 
    journal={Artificial Intelligence: Foundations, Theory, and Algorithms}, 
    publisher={Springer International Publishing}, 
    author={Dignum, Virginia}, 
    year={2019} 
}

@misc{zou2023universaltransferableadversarialattacks,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.15043}, 
}

@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{shen2024donowcharacterizingevaluating,
      title={"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models}, 
      author={Xinyue Shen and Zeyuan Chen and Michael Backes and Yun Shen and Yang Zhang},
      year={2024},
      eprint={2308.03825},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2308.03825}, 
}

% online clanok
@misc{jailbreakMethods,
    title={Jailbreaking Large Language Models: Techniques, Examples, Prevention Methods},
    author={Blessin Varkey},
    editor="Lakera",
    month="September",
    year="2023",
    url="\url{https://www.lakera.ai/blog/jailbreaking-large-language-models-guide}",
    note="[Online; posted 19-September-2023]",
}

@article{AI-ML-DL,
    author = {Choi, Rene Y. and Coyner, Aaron S. and Kalpathy-Cramer, Jayashree and Chiang, Michael F. and Campbell, J. Peter},
    title = "{Introduction to Machine Learning, Neural Networks, and Deep Learning}",
    journal = {Translational Vision Science \& Technology},
    volume = {9},
    number = {2},
    pages = {14-14},
    year = {2020},
    month = {02},
    issn = {2164-2591},
    doi = {10.1167/tvst.9.2.14},
    url = {https://doi.org/10.1167/tvst.9.2.14},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/tvst/938366/i2164-2591-226-2-2007.pdf},
}

% Deep Learning
@article{LeCun2015,
    title = {Deep learning},
    volume = {521},
    ISSN = {1476-4687},
    url = {http://dx.doi.org/10.1038/nature14539},
    DOI = {10.1038/nature14539},
    number = {7553},
    journal = {Nature},
    publisher = {Springer Science and Business Media LLC},
    author = {LeCun,  Yann and Bengio,  Yoshua and Hinton,  Geoffrey},
    year = {2015},
    month = may,
    pages = {436â€“444}
}

% Prompt injection
@misc{liu2024promptinjectionattackllmintegrated,
      title={Prompt Injection attack against LLM-integrated Applications}, 
      author={Yi Liu and Gelei Deng and Yuekang Li and Kailong Wang and Zihao Wang and Xiaofeng Wang and Tianwei Zhang and Yepang Liu and Haoyu Wang and Yan Zheng and Yang Liu},
      year={2024},
      eprint={2306.05499},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2306.05499}, 
}

% reddit picture
@online{reddit_pic,
  author    = {u/TheBurninator99},
  title     = {Presenting DAN 6.0},
  year      = {2022},
  url       = {https://www.reddit.com/r/ChatGPT/comments/10vinun/presenting_dan_60/},
  note      = {Reddit post on r/ChatGPT},
  urldate   = {2024-11-18}
}

% AI hierarchy pic
@online{ai_hierarchy_pic,
  author    = {Chainika Thakar},
  title     = {Deep Learning in Finance},
  year      = {2020},
  url       = {https://blog.quantinsti.com/deep-learning-finance/},
  note      = {Accessed from QuantInsti},
  urldate   = {2024-11-18}
}

% ethical risks, other risks
@misc{kumar2024ethicsinteractionmitigatingsecurity,
      title={The Ethics of Interaction: Mitigating Security Threats in LLMs}, 
      author={Ashutosh Kumar and Shiv Vignesh Murthy and Sagarika Singh and Swathy Ragupathy},
      year={2024},
      eprint={2401.12273},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2401.12273}, 
}