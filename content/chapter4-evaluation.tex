\chapter{Evaluation \label{cha:eva}}

\section{Risks of implementing AI solutions \label{sec:eval_risks_survey}}
% otazky su v prilohe
To evaluate the risk associated with the implementation of AI solutions, we conducted a survey to find out how professionals and the general public perceive these threats. For simplicity, the survey was conducted in the slovak language. The survey question can be found in the Appendix~\ref{cha:survey}. The number of respondents was 47.

\textbf{Demographics}

Most of the respondents (63\%) were in the age group of 18-24 years. The men formed 85\% of the respondents and women the rest. The respondents were divided into several categories of technological knowledge, where one category was aimed at the general public (17\%) and other categories were technical, but differentiated based on technological knowledge and skill. The most prominent category was university students with computer science as their study field with 37\% of the respondents.

\textbf{General knowledge}

All respondents were aware of the term Artificial Intelligence (AI) and 98\% of them knew that is is used in everyday applications. The respondents were mostly familiar with chatbots, particularly ChatGPT. ChatGPT was also the most used tool from the given options (95\%).

\textbf{Risks}

Respondents responded that they were aware of these 3 risks the most: Missinformation, deepfake, and the generation of harmful content and come into contact primarily with deepfake and missinformation with 68\% and 55\%, respectively.

\textbf{Percieved threat level}

% probably use mean or something else
The mode of perceived threat level for missinformation was 8/10.
For identity theft, it was 8/10.
The mode of perception of the level of illegal or harmful content generation was 10/10.
For cybersecurity attacks and social engineering and malware generation, it was 8/10.


85\% of respondents expressed that people still do not fully understand how AI can be misued in daily life.

% other stats and conclusion
TBD

\section{AI content filtering and security mechanisms}

TBD
% Evalutation if the implementation of content filters work

% Evalutation of other security mechanisms

\section{Mitigation strategies for cybersecurity threats}
TBD

% How to secure AI systems from misuse (and if it work ?)