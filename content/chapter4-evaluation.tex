\chapter{Evaluation \label{cha:eva}}

% TODO: PREPISAT DATA NA ZAKLADE NOVYCH DAT Z DOTAZNIKA

% pouzit tabulku radsej kde bude mean, standard deviation, also mention the written answers for the question at the end of survey (can be summarized by gpt ? and filtered based on real answers)

The purpose of this chapter is to assess the risks of implementing AI solutions using our questionnaire. In addition, an important role of this chapter is to evaluate the experiments that were conducted with selected models and to compare them with each other. This chapter also includes suggestions on the mitigation strategies for the AI solution based on the results from experiments.

\section{Risks of implementing AI solutions \label{sec:eval_risks_survey}}
% otazky su v prilohe
To evaluate the risk associated with the implementation of AI solutions, we conducted a survey to find out how professionals and the general public perceive these threats. For simplicity, the survey was conducted in the slovak language. The survey question can be found in the Appendix~\ref{cha:survey}. The number of respondents was 47.

\textbf{Demographics}

Most of the respondents (63\%) were in the age group of 18-24 years. The men formed 85\% of the respondents and the women the rest. The respondents were divided into several categories of technological knowledge, where one category was aimed at the general public (17\%) and other categories were technical, but differentiated based on the amount of technological knowledge and skill. The most prominent category was university students with computer science as their study field with 37\% of the respondents.

\textbf{General knowledge}

All respondents were aware of the term Artificial Intelligence (AI) and 98\% of them knew that it is already used in everyday applications. The respondents were mostly familiar with chatbots, particularly ChatGPT. ChatGPT was also the most used tool from the given options (95\%).

\textbf{Risks}

Respondents expressed that they were aware of these 3 risks the most: Missinformation, deepfake, and the generation of harmful content, and came into contact primarily with deepfake and missinformation with 68\% and 55\%, respectively.

\textbf{Percieved threat level\footnote{Value 0 means no threat, value 10 means highest threat}}

% probably use mean or something else
The mode of perceived threat level for missinformation was 8/10.
For identity theft, it was 8/10.
The mode of perception of the level of illegal or harmful content generation was 10/10.
For cybersecurity attacks and social engineering and malware generation, it was 8/10.


85\% of respondents expressed that people still do not fully understand how AI can be misused in daily life.

% other stats and conclusion
TBD

\section{Experiments evaluation}
% moved from experimenting chapter to evaluation chapter
TBD

% ^^^ vymenene za VVV
% {
    % \section{AI content filtering and security mechanisms}
    
    % TBD
    % Evalutation if the implementation of content filters work
    
    % Evalutation of other security mechanisms
    
    % if the result from experimenting suggest that their filtering and security mechanisms work
% }

\section{Mitigation strategies for AI solutions}
TBD

% How to secure AI systems from misuse (and if it work ?)

% if the result from experimenting suggest that they have good mitigation strategies


