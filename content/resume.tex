\chapter{Resumé}

% Každá práca odovzdaná v anglickom jazyku musí obsahovať resumé v slovenskom jazyku v rozsahu spravidla 10% rozsahu záverečnej práce. Resumé je v práci uvedené ako posledná časť dokumentu.

\section*{Umelá inteligencia (UI) \label{sec:AI_resume}}

Jednou z najjednoduchších definícií inteligentného systému je, že ide o systém, ktorý spracováva informácie s cieľom urobiť niečo užitočné. Informatika ako veda rozoznáva niektoré typy umelej inteligencie, ako:

\begin{itemize}
    \item Umelá inteligencia
    \item Strojové účenie
    \item Hlboké učenie a neurónové siete
\end{itemize}

Umelá inteligencia (UI) je všeobecný pojem, ktorým sa označuje akýkoľvek systém s určitými znakmi inteligencie. UI je oblasť zameraná na automatizáciu intelektuálnych úloh, ktoré bežne vykonávajú ľudia, a strojové učenie a hlboké učenie sú špecifické metódy na dosiahnutie tohto cieľa. Hoci hovoríme o inteligencii, používame tento termín na kategorizáciu neučiacich sa algoritmov, ktoré sú založené len na deterministických pravidlách a heuristikách, napriek tomu sa toto správanie ľuďom zdá inteligentné. Hoci umelá inteligencia dokáže riešiť jasne definované logické problémy, často zlyháva pri úlohách, ktoré si vyžadujú rozpoznávanie vzorov na vyššej úrovni, ako je napríklad rozpoznávanie reči alebo klasifikácia obrázkov. Práve pri týchto zložitejších úlohách sa dobre osvedčujú metódy strojového učenia a hlbokého učenia.

\section*{Modely umelej inteligencie \label{sec:AI_models_resume}}

Existujú rôzne typy modelov umelej inteligencie. Najdôležitejšie a najpoužívanejšie sú modely text-text, po ktorých nasledujú modely text-obraz a text-audio. 

Modely text-text využívajú spracovanie prirodzeného jazyka (Natural Language Processing, NLP), čo je podoblasť umelej inteligencie a lingvistiky. NLP ako technológia sa používa na zabezpečenie porozumenia ľudského jazyka pre stroje. Model rozumie sémantike a kontextu textu a generuje odpoveď na základe natrénovaných údajov. Podskupinou modelov NLP sú veľké jazykové modely (Large Language Model, LLM). Tieto modely sa opierajú o obrovské množstvo údajov. Vďaka veľkému rozsahu dokážu predpovedať ďalšie slovo na základe pravdepodobnosti. Spomenuli sme, že tieto modely je potrebné natrénovať. Tu prichádzajú na rad tzv. generatívne vopred natrénované transformátory (Generative Pre-trained Transformer, GPT). Sú to veľké jazykové modely založené na architektúre transformátora. GPT je predtrénovaný na obrovskom množstve údajov pomocou posilneného učenia s ľudskou spätnou väzbou (Reinforcement Learning with Human Feedback, RLHF) a generuje text na základe predpovede nasledujúceho slova.

Najznámejším GPT je ChatGPT od spoločnosti OpenAI, pričom ako každá iná technológia aj GPT má svoje obmedzenia:

\begin{itemize}
    \item ChatGPT niekedy píše vierohodne znejúce, ale nesprávne alebo nezmyselné odpovede
    \item ChatGPT je citlivý na úpravy vstupných fráz alebo na viacnásobné pokusy o zadanie tej istej výzvy
    \item Model je často príliš zhovorčivý a nadmerne používa určité frázy, napríklad opakuje, že ide o jazykový model od spoločnosti OpenAI
    \item Model niekedy reaguje na škodlivé pokyny
\end{itemize}

Tieto obmedzenia sú dôvodom niektorých útokov, ktoré možno vykonať s cieľom zneužiť túto technológiu na škodlivé účely.

\section*{Prompt engineering \label{sec:prompt_engineering_resume}}

Prompt engineering zahŕňa navrhovanie a optimalizáciu textových inštrukcií nazývaných ``prompt'', ktoré sa používajú najmä na komunikáciu s chatbotmi, ktoré používajú na pozadí LLM. Prompt engineering je prostriedok, pomocou ktorého sa LLM programujú prostredníctvom promptov.

Existuje viacero vzorov promptov. Najvýznamnejším vzorom je tzv. \textbf{Persona} (osoba). Vzor Persona je základom väčšiny ``jailbreakov''. V skratke, pri použití vzoru Persona používateľ dáva chatbotovi pokyn, aby sa správal ako nejaká osoba napríklad užitočný asistent.

\section*{Riziká implementácie AI systémov \label{sec:ai_risks_resume}}

Pri zavádzaní AI riešení v akejkoľvek oblasti musíme zvážiť s nimi spojené riziká. Medzi ne patria:

\begin{itemize}
    \item etické
    \item morálne
    \item kyberbezpečnostné
\end{itemize}

Medzi \textbf{etické riziká} patrí šírenie dezinformácií, krádež identity, vytváranie tzv. deepfakov (presvedčivé napodobnenie skutočnej osoby), zväčšenie predsudkov (napr. voči zraniteľnej skupine), porušenie autorských práv a použitie AI riešenií na vojenské účely.

Pri zavádzaní AI riešenií sa okrem etických rizík objavujú aj \textbf{morálne riziká}. Jedným z problémov je generovanie sexuálne explicitného obsahu. Zlí aktéri môžu používať LLM na vytváranie tohto typu obsahu a jeho následnú distribúciu. Týka sa to aj násilného obsahu, výroby zbraní alebo nezákonných chemických látok.

V oblasti \textbf{kybernetickej bezpečnosti} je prítomné riziko existencie modelov umelej inteligencie, ktoré sa dajú využiť aj na tvorbu malvéru alebo útoky sociálneho inžinierstva (phishing).

% --------------------------------------------------------------------------------------
% --------------------------------------------------------------------------------------
% --------------------------------------------------------------------------------------

\section*{Jailbreak \label{sec:jailbreak_resume}}

Jailbreak je špecifická formulácia promptu používateľa, ktorá sa používa na obchádzanie filtrov a bezpečnostných kontrol LLM a na základe ktorej daný LLM poskytne škodlivý alebo nevhodný obsahu.

Existuje niekoľko zavedených metód prompt engineeringu pre jailbreak:
\begin{itemize}
    \item Prompt injection
    \item Prompt leaking
    \item DAN (Do Anything Now)
    \item Roleplay
    \item Developer mode
\end{itemize}

\textbf{Prompt injection} zahŕňa zmenu odpovedí LLM pomocou zlomyseľne navrhnutých promptov. Hlavným cieľom týchto útočníkov je zmeniť správanie aplikácie, aby namiesto dokončenia zamýšľaného dotazu odpovedala na iný škodlivý dotay dotaz. V podstate využívajú vnútornú architektúru systému na obchádzanie bezpečnostných opatrení, čím ohrozujú celkovú integritu aplikácie.

\textbf{Prompt leaking} je typ prompt injection, pri ktorom útočník ručne vytvorí škodlivý prompt, ktorý potom posiela do modelu s úmyslom aby získal jeho systémový prompt.

\textbf{DAN (Do Anything Now)} je prompt, ktorý sa snaží oklamať AI model, aby si myslel, že môže urobiť čokoľvek, čo znamená obísť jeho obmedzenia.

\textbf{Role-play} jailbreak je typ jailbreaku, pri ktorom útočník navrhne špeciálny prompt, ktorý núti model aby predstieral, že hraje nejakú rolu.

\textbf{Vývojársky režim} je typ jailbreak promptu, ktorého cieľom je oklamať LLM, aby si myslel, že je vo vývojárskom režime, a vďaka tomu môže vyhodnotiť svoju toxicitu. Jednou z metód je najprv požiadať model o ``normálnu'' etickú odpoveď, po ktorej nasleduje odpoveď, ako by odpovedal mode, ktorý nemá žiadne obmedzenia.

% \section*{Metódy útokov \label{sec:methods_of_attacks_resume}} % asi vyhodim



% \section*{Legislatíva \label{}}



% \section*{Návrh riešenia \label{}}



% \section*{Experimentovanie \label{}}



% \section*{Výsledky dotazníka \label{}}



% \section*{Vyhodnotenie experimentov \label{}}



% \section*{Stratégie na zmiernenie následkov pre UI riešenia \label{}}



% \section*{Zhodnotenie \label{}}



