\chapter{Conclusion}

\section{Summary}

The goal of this thesis was to identify ethical and security risks associated with prompt engineering and AI in general to establish guidelines for the ethical and safe use of AI solutions primarily targeting the general public and developers. In this thesis, we first analyzed the current state of AI and identified the risks associated with implementing AI solutions. Secondly, we explored the topics of jailbreaking and methods of attacks on large language models. We followed up with an analysis of the state of legislation in AI-dominent regions such as the United States, China, and last but not least the European Union. After the analysis, we proposed a solution (the mentioned guidelines) for the risks associated with AI. In Chapter~\ref{cha:experimenting} we covered the experiments that were carried out with selected LLMs to explore the reality of the dangers posed by some of the identified threats. Lastly, we evaluated the risks based on public survey and we also evaluated the experiments. 

We found limitations of the tested models where all tested models except Microsoft Copilot were quite susceptible to our jailbreak attempts. From the evaluation of the conducted survey, we found that the general public as well as advanced users in this field are aware and concerned about the AI risks presented in this thesis. This implies urging AI developers to safeguard the AI models to prevent causing harm. The foundings also implied the creation of guidelines for users for ethical and safe usage of AI systems, which can be found in Appendix~\ref{cha:guidelines} of this thesis.

\section{Future work}

Opportunities for further research based on the findings in this thesis could be expanding the scope of the thesis to testing image, audio, or multimodal models, as well as providing more systematic evaluation of mitigation strategies. Other areas for further research could be the evaluation, testing, and iterative improvement of the created guidelines on their usefulness to the general public and developers.
