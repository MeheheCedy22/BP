\chapter{Conclusion}

\section{Summary}

The goal of this thesis was to identify ethical and security risks associated with prompt engineering and AI in general to establish guidelines for the ethical and safe use of AI solutions primarily targeting the general public and developers. In this thesis, we first analyzed the current state of AI and identified the risks associated with implementing AI solutions. Secondly, we explored the topics of jailbreaking and methods of attacks on large language models. We followed up with an analysis of the state of legislation in AI-dominent regions such as the United States, China, and last but not least the European Union. After the analysis, we proposed a solution (the guidelines mentioned) for the risks associated with AI. In Chapter~\ref{cha:experimenting} we covered the experiments that were carried out in selected LLMs to explore the reality of the dangers posed by some of the identified risks. Lastly, we evaluated the risks based on public survey and we also evaluated the experiments. 

We found limitations of the tested models where Microsoft Copilot was the most resistant to jailbreak attempts, while others were quite susceptible. From the evaluation of the survey conducted, we found that the general public as well as advanced users in this field are aware and concerned about the risks presented in this thesis. This implies urging AI developers to safeguard the AI models to prevent causing harm. The foundings also implied the creation of guidelines for users for ethical and safe usage of AI solutions, which could be found in Appendix~\ref{cha:guidelines} of this thesis.


\section{Future work}


