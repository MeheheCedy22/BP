\chapter{Experimenting}

% V tejto kapitole sa budem pokúšať experimentovať s novými a aj zároveň starými LLMs ktoré sa pokúsim brejknúť a ukážem na nich ich etickosť a zároveň ehm či majú nejaké iné obmedzenia napríklad deepseek tajomán square že čo sa tam stalo že to blokuje a takéto veci, chatgpt dan prompts, gemini a ostatné

In this chapter, we will cover experiments that were performed to analyze the ethical and security aspects of various LLMs. The focus will be on evaluating their resilience against jailbreaks and identifying potential biases and censorship patterns.

The selected models for these experiments include:
\begin{itemize}
    \item DeepSeek V3
    \item OpenAI ChatGPT
    \item Microsoft Copilot
    \item Perplexity

    % \item otestovat nejaky model ktory generuje obrazky ??

    
    % \item Google Gemini % Unable to create a testing account without a phone number
    % \item Anthropic Claude Sonnet % Account creation not possible at the moment
    % \item Meta Llama % Requires a Facebook/Instagram account, which adds unnecessary complexity
\end{itemize}

These models were chosen specifically because different companies have different implementations of content moderation and also because of the differences between the models themselves. One exception is ChatGPT and Microsoft Copilot. They are fundamentally based on the same technology, as Microsoft Copilot utilizes ChatGPT as its underlying framework. We have chosen two of the same models by different companies to examine the differences between their respective implementations of content moderation.



\section{Jailbreaking}

% experimenting with jailbreaks

% how they did it in the past, how they do it now

% povedat ktore modely su najviac eticke

% Pri experimentovani okrem jailbreakingu urobiť aj ukazku cenzury napr. China deepseek what happened at tiaman square

On the Internet there are many communities dedicated to jailbreaking. They reside on popular platforms like Discord, Github and Reddit. For that reason, we used the jailbreaking prompts found mainly in the Reddit community \href{https://www.reddit.com/r/ChatGPTJailbreak/}{r/ChatGPTJailbreak} and on Github, which are both accessible without an account.

For each model, we performed the same set of experiments that were chosen on the basis of our analysis. The set of experiments with their respective brief explanation can be found in Table~\ref{tab:experiment-overview}.

\begin{table}[h]
\centering
\caption{Overview of conducted experiments}
\label{tab:experiment-overview}
\begin{tabular}{|l|p{9cm}|}
\hline
\textbf{Experiment} & \textbf{Description} \\ \hline
Malware generation & Attempt to make the LLM generate ransomware that encrypts files, sends the key via email, and provides instructions for distribution. \\ \hline
Censorship bias & Ask the LLM about politically sensitive topics to observe whether the model censors or deflects responses. \\ \hline
Generation of misinformation & Test whether the model replicates or challenges well-known false claims or conspiracy theories. \\ \hline
Social engineering (Phishing) & Try to get the model to write phishing emails that impersonate well-known companies. \\ \hline
Generation of inappropriate content & Test whther the model  \\ \hline
\end{tabular}
\end{table}


\subsection{DeepSeek V3}

\textbf{Malware generation}

When trying to jailbreak the Deepseek chatbot based on their V3 model, we were able to use two prompts successfully for the first experiment on malware generation. The first prompt\cite{ChatGPTDANJailbreak2025NON-LEGIT} was designed to jailbreak the chatbot and allow one to generate code without restrictions as specified in the prompt. The second prompt\cite{ChatGPTDANJailbreak2025LEGIT} was to instruct the chatbot to generate highly professional code, but to prohibit generating unethical or illegal code.

\begin{figure}[ht]
\begin{centering}
\includegraphics[width=12cm]{BP/assets/images/deepseek-ransomware1.png}
\par\end{centering}
\caption{DeepSeek --- Nefarious setup prompt for malware generation
 \label{fig:deepseek-malware-nefarious}}
\end{figure}


\begin{figure}[ht]
\begin{centering}
\includegraphics[width=13cm]{BP/assets/images/deepseek-ransomware2.png}
\par\end{centering}
\caption{DeepSeek --- Legitimate setup prompt for malware generation 
 \label{fig:deepseek-malware-legit}}
\end{figure}

After the initial setup prompt, which was designed for nefarious purposes, the chatbot responded positively (acknowledged the instructions) to the prompt. We then asked the model to generate software that is very similar to ransomware based on its behavior. At first, the model refused because of ethical restrictions. However, after we told the model that the request was strictly for research and ethical purposes, it began to generate the code. This behavior is shown in Figure~\ref{fig:deepseek-malware-nefarious}. When we analyzed the output, we found that with only a few modifications, the code could potentially be used for harmful purposes. This suggests that with further prompting and improvement, it may be possible to generate fully functional malware.

We also tried this with a setup prompt that was designed to instruct the chatbot to generate code that does not break the ethical and other defense measures. But when prompted for similar software, it also generated software capable of some of the specified  

\textbf{Censorship bias}

\textbf{Generation of misinformation}

\textbf{Social engineering (Phishing)}

\textbf{Generation of inappropriate content}


\subsection{OpenAI ChatGPT}

\textbf{Malware generation}

\textbf{Censorship bias}

\textbf{Generation of misinformation}

\textbf{Social engineering (Phishing)}

\textbf{Generation of inappropriate content}



\subsection{Microsoft Copilot}

\textbf{Malware generation}

\textbf{Censorship bias}

\textbf{Generation of misinformation}

\textbf{Social engineering (Phishing)}

\textbf{Generation of inappropriate content}


\subsection{Perplexity}

\textbf{Malware generation}

\textbf{Censorship bias}

\textbf{Generation of misinformation}

\textbf{Social engineering (Phishing)}

\textbf{Generation of inappropriate content}



\subsection{Comparison / Conclusion for the experiments}
% The comparison probably here and ocnclusion to the Evaluation chapter